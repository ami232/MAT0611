{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df33ee9f",
   "metadata": {},
   "source": [
    "# Maximum Likelihood Estimation - Programming Exercises\n",
    "**MAD-B3-2526-S2-MAT0611**\n",
    "\n",
    "This notebook contains all programming exercises for the MLE session."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc08832",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 1: Normal Distribution Sampling\n",
    "\n",
    "**Task**: \n",
    "1. Simulate $n=50$ samples from $N(5, 4)$\n",
    "2. Compute MLE for $\\mu$ and $\\sigma^2$\n",
    "3. Repeat 1000 times and visualize sampling distributions\n",
    "\n",
    "**Learning objectives**:\n",
    "- Understand sampling distributions of MLEs\n",
    "- Verify bias in $\\hat{\\sigma}^2_{\\text{MLE}}$\n",
    "- Observe asymptotic normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4575371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Parameters\n",
    "true_mu = 5\n",
    "true_sigma2 = 4\n",
    "n = 50\n",
    "n_simulations = 1000\n",
    "\n",
    "# TODO: Create arrays to store estimates\n",
    "mu_estimates = np.zeros(n_simulations)\n",
    "sigma2_estimates = np.zeros(n_simulations)\n",
    "\n",
    "# TODO: Implement simulation loop\n",
    "for i in range(n_simulations):\n",
    "    # Generate sample from N(5, 4)\n",
    "    sample = None  # Your code here\n",
    "\n",
    "    # Compute MLEs\n",
    "    mu_estimates[i] = None  # Your code here\n",
    "    sigma2_estimates[i] = None  # Your code here\n",
    "\n",
    "print(f\"Simulation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e2cdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create visualizations\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot sampling distribution of mu_hat\n",
    "# Your code here\n",
    "\n",
    "# Plot sampling distribution of sigma2_hat\n",
    "# Your code here\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f2fe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compute and display summary statistics\n",
    "print(\"=\" * 60)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nμ estimates:\")\n",
    "print(f\"  True value:     {true_mu}\")\n",
    "# Add more statistics here\n",
    "\n",
    "print(f\"\\nσ² estimates:\")\n",
    "print(f\"  True value:     {true_sigma2}\")\n",
    "# Add more statistics here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5872e1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Bonus: Fisher Information for Normal Distribution\n",
    "\n",
    "**Task**: Derive the Fisher Information for a normal distribution and compare with simulation results. For $\\mu$ and $\\sigma^2$, you should obtain this:\n",
    "\n",
    "$$\n",
    "\\mathcal{I}(\\mu, \\sigma^2) = \\begin{pmatrix}\n",
    "\\frac{1}{\\sigma^2} & 0 \\\\\n",
    "0 & \\frac{1}{2\\sigma^4}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Remember the MLE is asymptotically normal with variance given by the inverse of the Fisher Information. \n",
    "\n",
    "$$\\sqrt{n}(\\hat{\\theta}_{\\text{MLE}} - \\theta) \\xrightarrow{d} N(0, I(\\theta)^{-1})$$\n",
    "\n",
    "**Questions to answer**:\n",
    "\n",
    "1. **Calculate the theoretical standard error** of $\\hat{\\mu}_{\\text{MLE}}$ using Fisher Information for a single observation, then for $n$ observations.\n",
    "\n",
    "2. **For our simulation** with $\\mu = 5$, $\\sigma^2 = 4$, $n = 50$:\n",
    "   - Calculate the theoretical standard error of $\\hat{\\mu}$\n",
    "   - Compare with the empirical standard error from your simulation results above\n",
    "\n",
    "3. **Calculate the Fisher Information for $\\sigma^2$**:\n",
    "   - Derive the theoretical standard error of $\\hat{\\sigma}^2$\n",
    "   - Calculate it for our simulation parameters\n",
    "   - Compare with your empirical results\n",
    "\n",
    "4. **Interpretation**: \n",
    "   - How well do the theoretical predictions match your simulation?\n",
    "   - What does this tell you about the asymptotic properties of MLEs?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f294b4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 2: Poisson Distribution MLE\n",
    "\n",
    "**Task**:\n",
    "1. Generate Poisson data with $\\lambda = 3$\n",
    "2. Implement numerical MLE using scipy.optimize\n",
    "3. Compare with analytical solution\n",
    "\n",
    "**Learning objectives**:\n",
    "- Implement negative log-likelihood function\n",
    "- Use numerical optimization\n",
    "- Verify analytical vs numerical agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ab35bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate Poisson data\n",
    "np.random.seed(42)\n",
    "true_lambda = 3\n",
    "n = 100\n",
    "data = np.random.poisson(true_lambda, n)\n",
    "\n",
    "# TODO: Compute analytical MLE\n",
    "mle_analytical = None  # Your code here\n",
    "\n",
    "print(f\"True parameter λ: {true_lambda}\")\n",
    "print(f\"Analytical MLE:   {mle_analytical:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898cb493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define negative log-likelihood for Poisson\n",
    "def neg_log_likelihood_poisson(lam, data):\n",
    "    \"\"\"\n",
    "    Compute negative log-likelihood for Poisson distribution.\n",
    "\n",
    "    Parameters:\n",
    "    - lam: parameter value\n",
    "    - data: observed data\n",
    "\n",
    "    Returns:\n",
    "    - negative log-likelihood value\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55207618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Numerical optimization\n",
    "result = minimize(\n",
    "    neg_log_likelihood_poisson,\n",
    "    x0=[1.0],  # initial guess\n",
    "    args=(data,),\n",
    "    method=\"L-BFGS-B\",\n",
    "    bounds=[(0.001, None)],\n",
    ")\n",
    "\n",
    "mle_numerical = result.x[0]\n",
    "\n",
    "print(f\"Numerical MLE:    {mle_numerical:.6f}\")\n",
    "print(f\"Difference:       {abs(mle_analytical - mle_numerical):.10f}\")\n",
    "print(f\"Optimization success: {result.success}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1d3232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot likelihood function\n",
    "lambdas = np.linspace(2, 4, 200)\n",
    "log_likelihoods = None  # Your code here\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Your plotting code here\n",
    "plt.xlabel(\"λ\", fontsize=12)\n",
    "plt.ylabel(\"Log-Likelihood\", fontsize=12)\n",
    "plt.title(\"Poisson Log-Likelihood Function\", fontsize=14)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c046e136",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 3: Bernoulli Likelihood Surface\n",
    "\n",
    "**Task**:\n",
    "1. Create likelihood surface plot for Bernoulli parameter\n",
    "2. Use observed data: $[1, 1, 0, 1, 0, 0, 1, 1, 1, 0]$\n",
    "3. Mark the MLE on the plot\n",
    "\n",
    "**Learning objectives**:\n",
    "- Visualize likelihood and log-likelihood functions\n",
    "- Understand shape of likelihood surface\n",
    "- Verify MLE at maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f58029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Observed data\n",
    "data = np.array([1, 1, 0, 1, 0, 0, 1, 1, 1, 0])\n",
    "n = len(data)\n",
    "sum_x = np.sum(data)\n",
    "\n",
    "# TODO: Compute analytical MLE\n",
    "mle_analytical = None  # Your code here\n",
    "\n",
    "print(f\"Data: {data}\")\n",
    "print(f\"Number of successes: {sum_x}\")\n",
    "print(f\"Sample size: {n}\")\n",
    "print(f\"MLE p̂ = {mle_analytical:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c91ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define likelihood and log-likelihood functions\n",
    "def likelihood_bernoulli(p, data):\n",
    "    \"\"\"Compute likelihood for Bernoulli distribution.\"\"\"\n",
    "    # Your code here\n",
    "    pass\n",
    "\n",
    "\n",
    "def log_likelihood_bernoulli(p, data):\n",
    "    \"\"\"Compute log-likelihood for Bernoulli distribution.\"\"\"\n",
    "    # Your code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ce9ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Generate p values and compute likelihoods\n",
    "p_values = np.linspace(0.01, 0.99, 200)\n",
    "likelihoods = None  # Your code here\n",
    "log_likelihoods = None  # Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04d3a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Likelihood plot\n",
    "# Your code here\n",
    "\n",
    "# Log-likelihood plot\n",
    "# Your code here\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
